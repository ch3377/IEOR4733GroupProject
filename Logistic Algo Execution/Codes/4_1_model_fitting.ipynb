{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.linear_model.logistic import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fucntions of this notebook:\n",
    "* Read indicator data (\"ticker_indicator.csv\" in directory \".../Data/indicator\", generated by 2_tech_indicator_calculation)\n",
    "* Split sample into training set and test set\n",
    "* Fit two logistic regression models, one with all indicators and one with indicators selected by stepwise process (generated by 3_stepwise_selection)\n",
    "* Output predicted direction and probability for test set as one .csv file (with name \"ticker_signal.csv\" and stored in directory \".../Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_working = \"/Users/user/Desktop/E4733 AT/Project/Coding Environment/Codes\"\n",
    "os.chdir(dir_working)\n",
    "dir_data = \"../Data/indicator\"\n",
    "dir_output = \"../Output\"\n",
    "#!# set ticker list \n",
    "ticker_list = ['aapl', 'amzn', 'nvda', 'amd', 'msft', 'fb', 'nflx', \\\n",
    "               'goog', 'intc', 'pypl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Indicator Sets Selected by Stepwise Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_set = [['MA_CAT_15','MA_CAT_30','VMA_Cat_3','VMA_Cat_15', \\\n",
    "                'VMA_Cat_20','MACD_CAT_3_5','MACD_CAT_5_15','MACD_CAT_10_15',\\\n",
    "                'MACD_CAT_15_30','WilliamR','RSI_20','PSY_15','PSY_30','ADO',\\\n",
    "                'K_D_CAT_5_3','K_D_CAT_B_15_80_20'],\\\n",
    "               ['MA_CAT_5','MA_CAT_15','MA_CAT_20','MA_CAT_30','VMA_Cat_3',\\\n",
    "                'VMA_Cat_5','VMA_Cat_10','VMA_Cat_20','MACD_CAT_3_5',\\\n",
    "                'MACD_CAT_5_10','MACD_CAT_15_30','WilliamR','RSI_10','PSY_10',\\\n",
    "                'ADO','K_D_CAT_5_3','K_D_CAT_B_5_80_20'],\\\n",
    "               ['MA_CAT_20','VMA_Cat_3','VMA_Cat_10','VMA_Cat_15',\\\n",
    "                'VMA_Cat_20','MACD_CAT_3_5','MACD_CAT_5_15','WilliamR',\\\n",
    "                'RSI_10','RSI_20','RSI_30','PSY_10','ADO','K_D_CAT_5_3',\\\n",
    "                'K_D_CAT_B_5_80_20','K_D_CAT_B_15_80_20'],\\\n",
    "               ['MA_CAT_3','MA_CAT_5','VMA_Cat_15','MACD_CAT_3_5',\\\n",
    "                'MACD_CAT_5_30','MACD_CAT_10_15','WilliamR','PSY_10','PSY_15',\\\n",
    "                'PSY_30','ADO','K_D_CAT_15_3','K_D_CAT_5_3',\\\n",
    "                'K_D_CAT_B_15_80_20','CCI_5'],\\\n",
    "               ['MA_CAT_3','MA_CAT_10','VMA_Cat_20','MACD_CAT_5_15',\\\n",
    "                'WilliamR','PSY_10','ADO','K_D_CAT_15_3'],\\\n",
    "               ['MA_CAT_3','VMA_Cat_3','VMA_Cat_5','VMA_Cat_15',\\\n",
    "                'MACD_CAT_3_5','MACD_CAT_5_10','MACD_CAT_10_20','WilliamR',\\\n",
    "                'RSI_20','PSY_10','ADO','K_D_CAT_15_3','K_D_CAT_B_15_80_20',\\\n",
    "                'CCI_5'],\\\n",
    "               ['MA_CAT_3','MA_CAT_5','MA_CAT_15','MA_CAT_20','VMA_Cat_15',\\\n",
    "                'MACD_CAT_3_5','MACD_CAT_10_15','WilliamR','RSI_10','PSY_10',\\\n",
    "                'ADO'],\\\n",
    "               ['VMA_Cat_3','VMA_Cat_5','VMA_Cat_30','MACD_CAT_3_5',\\\n",
    "                'MACD_CAT_5_10','MACD_CAT_5_30','MACD_CAT_10_15','WilliamR',\\\n",
    "                'RSI_10','PSY_10','ADO','K_D_CAT_5_3','K_D_CAT_B_5_80_20',\\\n",
    "                'K_D_CAT_B_15_80_20','CCI_5'],\\\n",
    "               ['MA_CAT_3','MA_CAT_30','VMA_Cat_10','MACD_CAT_3_5',\\\n",
    "                'MACD_CAT_5_15','MACD_CAT_5_30','WilliamR','RSI_10','PSY_10',\\\n",
    "                'ADO','K_D_CAT_5_3','K_D_CAT_B_5_80_20','K_D_CAT_B_15_80_20'],\\\n",
    "               ['MA_CAT_15','VMA_Cat_5','MACD_CAT_3_5','MACD_CAT_5_15',\\\n",
    "                'MACD_CAT_5_30','MACD_CAT_10_15','WilliamR','RSI_10','PSY_10',\\\n",
    "                'ADO','K_D_CAT_5_3','K_D_CAT_B_15_80_20']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_optimal(ticker = 'aapl',indicator_set = optimal_set[0]):\n",
    "    ## read & clean data\n",
    "    data = pd.read_csv(dir_data + '/' + ticker + '_indicator.csv')\n",
    "    data.time = pd.to_datetime(data.time)\n",
    "    data = data.set_index('time', drop = True)\n",
    "    data.direction = data.direction.shift(-1)\n",
    "    data['return'] = data['return'].shift(-1)\n",
    "    data = data.dropna()\n",
    "    ## training & test sets \n",
    "    data['date'] = data.index.date\n",
    "    # training set \n",
    "    data_train = data.where(data.date < dt.date(2018,12,17))\n",
    "    data_train = data_train.dropna()\n",
    "    data_train = data_train.drop('date', axis = 1)\n",
    "    # test set \n",
    "    data_test = data.where(data.date >= dt.date(2018,12,17))\n",
    "    data_test = data_test.dropna()\n",
    "    data_test = data_test.drop('date', axis = 1)\n",
    "    \n",
    "    ## Logistic Full Model\n",
    "    # values \n",
    "    X_train = data_train.loc[:,list(data_train.columns)[11:]].values\n",
    "    Y_train = data_train.loc[:,'direction'].values\n",
    "    X_test = data_test.loc[:,list(data_train.columns)[11:]].values\n",
    "    Y_test = data_test.loc[:,'direction'].values\n",
    "    # model\n",
    "    logistic_model = LogisticRegression(solver = 'lbfgs', max_iter = 1000) \n",
    "    logistic_model.fit(X_train, Y_train) \n",
    "    acc_in_logistic_full = np.mean(logistic_model.predict(X_train) == Y_train)\n",
    "    Y_pred_logistic_full = logistic_model.predict(X_test)\n",
    "    acc_out_logistic_full = np.mean(Y_pred_logistic_full == Y_test)\n",
    "    logistic_proba_full = logistic_model.predict_proba(X_test)\n",
    "    \n",
    "    ## Logistic Stepwise Optimized \n",
    "    # values \n",
    "    X_train = data_train.loc[:,indicator_set].values\n",
    "    Y_train = data_train.loc[:,'direction'].values\n",
    "    X_test = data_test.loc[:,indicator_set].values\n",
    "    Y_test = data_test.loc[:,'direction'].values\n",
    "    # model\n",
    "    logistic_model = LogisticRegression(solver = 'lbfgs', max_iter = 1000) \n",
    "    logistic_model.fit(X_train, Y_train) \n",
    "    acc_in_logistic = np.mean(logistic_model.predict(X_train) == Y_train)\n",
    "    Y_pred_logistic = logistic_model.predict(X_test)\n",
    "    acc_out_logistic = np.mean(Y_pred_logistic == Y_test)\n",
    "    logistic_proba = logistic_model.predict_proba(X_test)\n",
    "    \n",
    "    ## Output & Return \n",
    "    data_test['signal_logistic_full'] = Y_pred_logistic_full\n",
    "    data_test['logistic_prob_full'] = np.max(logistic_proba_full, axis = 1)\n",
    "    data_test['signal_logistic'] = Y_pred_logistic\n",
    "    data_test['logistic_prob'] = np.max(logistic_proba, axis = 1)\n",
    "    data_output = data_test.drop(list(data_train.columns)[11:], axis = 1)\n",
    "    data_output.to_csv(dir_output + '/' + ticker + '_signal.csv')\n",
    "    return [acc_in_logistic_full,acc_out_logistic_full,\\\n",
    "            acc_in_logistic,acc_out_logistic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "aapl\n",
      "Full Model:\n",
      "in-sample:  0.7315003394433129\n",
      "out-of-sample:  0.7295694766692447\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7316458151488702\n",
      "out-of-sample:  0.7308584686774942 \n",
      "\n",
      "\n",
      "amzn\n",
      "Full Model:\n",
      "in-sample:  0.7222141225640278\n",
      "out-of-sample:  0.7246451612903225\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7226029061573601\n",
      "out-of-sample:  0.7241290322580645 \n",
      "\n",
      "\n",
      "nvda\n",
      "Full Model:\n",
      "in-sample:  0.7277991338620992\n",
      "out-of-sample:  0.7272252675541634\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7275558366989441\n",
      "out-of-sample:  0.7280083529104673 \n",
      "\n",
      "\n",
      "amd\n",
      "Full Model:\n",
      "in-sample:  0.7309619969831151\n",
      "out-of-sample:  0.7346193952033369\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7306700403873291\n",
      "out-of-sample:  0.7361835245046924 \n",
      "\n",
      "\n",
      "msft\n",
      "Full Model:\n",
      "in-sample:  0.7376218323586745\n",
      "out-of-sample:  0.7404619776797301\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7371345029239766\n",
      "out-of-sample:  0.7386452115234882 \n",
      "\n",
      "\n",
      "fb\n",
      "Full Model:\n",
      "in-sample:  0.7298204641658153\n",
      "out-of-sample:  0.7358294331773271\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7297718094682042\n",
      "out-of-sample:  0.734009360374415 \n",
      "\n",
      "\n",
      "nflx\n",
      "Full Model:\n",
      "in-sample:  0.7170684197711225\n",
      "out-of-sample:  0.7161776162035834\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7179449719990261\n",
      "out-of-sample:  0.7161776162035834 \n",
      "\n",
      "\n",
      "goog\n",
      "Full Model:\n",
      "in-sample:  0.6806796543137542\n",
      "out-of-sample:  0.6929614873837981\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.6799472681997949\n",
      "out-of-sample:  0.6895086321381142 \n",
      "\n",
      "\n",
      "intc\n",
      "Full Model:\n",
      "in-sample:  0.7294341649172484\n",
      "out-of-sample:  0.7259397494001599\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.728408924473954\n",
      "out-of-sample:  0.7286057051452945 \n",
      "\n",
      "\n",
      "pypl\n",
      "Full Model:\n",
      "in-sample:  0.7313440125024419\n",
      "out-of-sample:  0.7263017356475301\n",
      "Stepwise Optimized:\n",
      "in-sample:  0.7311974995116234\n",
      "out-of-sample:  0.7249666221628839 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ticker_list)):\n",
    "    summary_list = model_fit_optimal(ticker_list[i])\n",
    "    print('\\n'+ticker_list[i])\n",
    "    print('Full Model:')\n",
    "    print('in-sample: ', summary_list[0])\n",
    "    print('out-of-sample: ', summary_list[1])\n",
    "    print('Stepwise Optimized:')\n",
    "    print('in-sample: ', summary_list[2])\n",
    "    print('out-of-sample: ', summary_list[3], '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
