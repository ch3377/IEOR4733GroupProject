{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions of this notebook:\n",
    "* Read raw data downloaded from Canvas (stored in directory \".../Data/raw\")\n",
    "* Combine data by stock\n",
    "* Outputs one .csv file for every stock (with name \"ticker.csv\" and stored in directory \".../Data/cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: \n",
    "* Data at 16:00 is removed due to some abnormal pattern observed in volume data. \n",
    "* Different folders contaning different stocks. Only stocks appearing in all folders are included in the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directory Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_working = \"/Users/user/Desktop/E4733 AT/Project/Coding Environment/Codes\"\n",
    "os.chdir(dir_working)\n",
    "dir_data = \"../Data/raw\"\n",
    "dir_output = \"../Data/cleaned\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. List of All Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folder = os.listdir(dir_data)\n",
    "p_ds_store = all_folder.count('.DS_Store') \n",
    "if p_ds_store != 0:\n",
    "    p_ds_store = all_folder.index('.DS_Store')\n",
    "    del all_folder[p_ds_store]\n",
    "del(p_ds_store)\n",
    "all_folder.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Processing the First Folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all files in the first folder\n",
    "dir_data_t = dir_data + '/' + all_folder[0]\n",
    "allfile = os.listdir(dir_data_t)\n",
    "p_ds_store = allfile.count('.DS_Store') \n",
    "if p_ds_store != 0:\n",
    "    p_ds_store = allfile.index('.DS_Store')\n",
    "    del allfile[p_ds_store]\n",
    "del(p_ds_store)\n",
    "allfile.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists of tickers and data \n",
    "ticker_list = []\n",
    "data_list = []\n",
    "for i in range(len(allfile)):\n",
    "    # get ticker name\n",
    "    ticker_list.append(allfile[i].split('_')[1].split('.')[0])\n",
    "    # process the data\n",
    "    data = pd.read_csv(dir_data_t + '/' + allfile[i], header = None, \\\n",
    "                       names = ['date','time','open','high','low','close',\\\n",
    "                                'volume','splits','earnings','dividend'])\n",
    "    # construct time index\n",
    "    data.time = data.time.apply(str)\n",
    "    data['time_len'] = data.time.apply(len)\n",
    "    data.loc[data.time_len == 3, 'time_adjust'] = '0'\n",
    "    data.loc[data.time_len != 3, 'time_adjust'] = ''\n",
    "    data.time = data.time_adjust + data.time\n",
    "    data['date_time'] = data.date.apply(str) + ' ' + data.time\n",
    "    data.time = pd.to_datetime(data.date_time,format = '%Y%m%d %H:%M')\n",
    "    data = data.set_index('time', drop = True)\n",
    "    # trading hours \n",
    "    data['time'] = data.index.time\n",
    "    data = data.where((data.time >= dt.time(9,30,0)) & \\\n",
    "                      (data.time <= dt.time(15,59,0)))\n",
    "    data = data.dropna()\n",
    "    # remove additional columns \n",
    "    data = data.drop(['date','time_len','time_adjust','date_time','time'],\\\n",
    "                     axis=1)\n",
    "    # fill missing data \n",
    "    data.open = data.open.resample('T').last().ffill()\n",
    "    data.high = data.high.resample('T').last().ffill()\n",
    "    data.low = data.low.resample('T').last().ffill()\n",
    "    data.close = data.close.resample('T').last().ffill()\n",
    "    data.volume = data.volume.resample('T').last().ffill()\n",
    "    data.splits = data.splits.resample('T').last().ffill()\n",
    "    data.earnings = data.earnings.resample('T').last().ffill()\n",
    "    data.dividend = data.dividend.resample('T').last().ffill()\n",
    "    # append to data_list\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store values in allfile as allfile0 for future use\n",
    "allfile0 = allfile "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing Remaining Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(all_folder)):\n",
    "    # list of all files \n",
    "    dir_data_t = dir_data + '/' + all_folder[i]\n",
    "    allfile = os.listdir(dir_data_t)\n",
    "    p_ds_store = allfile.count('.DS_Store') \n",
    "    if p_ds_store != 0:\n",
    "        p_ds_store = allfile.index('.DS_Store')\n",
    "        del allfile[p_ds_store]\n",
    "    del(p_ds_store)\n",
    "    allfile.sort()\n",
    "    # find intersection of allfile and allfile0\n",
    "    allfile_new = list(set(allfile0) & set(allfile))\n",
    "    allfile_new.sort()\n",
    "    for j in range(len(allfile0)):\n",
    "        if allfile0[j] not in allfile_new:\n",
    "            del ticker_list[j]\n",
    "            del data_list[j]\n",
    "    allfile0 = allfile_new # update allfile0\n",
    "    # process each file\n",
    "    for j in range(len(allfile)):\n",
    "        # check if file j in in the list \n",
    "        if allfile[j] not in allfile0:\n",
    "            continue \n",
    "        # read and clean data\n",
    "        p_file = allfile0.index(allfile[j]) # index of ticker\n",
    "        data = pd.read_csv(dir_data_t + '/' + allfile[j], header = None, \\\n",
    "                           names = ['date','time','open','high','low','close',\\\n",
    "                                    'volume','splits','earnings','dividend'])\n",
    "        data.time = data.time.apply(str)\n",
    "        data['time_len'] = data.time.apply(len)\n",
    "        data.loc[data.time_len == 3, 'time_adjust'] = '0'\n",
    "        data.loc[data.time_len != 3, 'time_adjust'] = ''\n",
    "        data.time = data.time_adjust + data.time\n",
    "        data['date_time'] = data.date.apply(str) + ' ' + data.time\n",
    "        data.time = pd.to_datetime(data.date_time,format = '%Y%m%d %H:%M')\n",
    "        data = data.set_index('time', drop = True)\n",
    "        data['time'] = data.index.time\n",
    "        data = data.where((data.time >= dt.time(9,30,0)) & \\\n",
    "                          (data.time <= dt.time(15,59,0)))\n",
    "        data = data.dropna()\n",
    "        data = data.drop(['date','time_len','time_adjust','date_time','time'],\\\n",
    "                         axis=1)\n",
    "        # fill missing data \n",
    "        data.open = data.open.resample('T').last().ffill()\n",
    "        data.high = data.high.resample('T').last().ffill()\n",
    "        data.low = data.low.resample('T').last().ffill()\n",
    "        data.close = data.close.resample('T').last().ffill()\n",
    "        data.volume = data.volume.resample('T').last().ffill()\n",
    "        data.splits = data.splits.resample('T').last().ffill()\n",
    "        data.earnings = data.earnings.resample('T').last().ffill()\n",
    "        data.dividend = data.dividend.resample('T').last().ffill()\n",
    "        # append the data to corresponding dataframe \n",
    "        data_list[p_file] = pd.concat([data_list[p_file],data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Output as .csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ticker_list)):\n",
    "    file_name = dir_output + '/' + ticker_list[i] + '.csv'\n",
    "    data_list[i].to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
